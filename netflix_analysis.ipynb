{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Introdução\n",
    "\n",
    "No cenário contemporâneo de entretenimento digital, a análise de dados desempenha um papel crucial na compreensão das preferências do público e no direcionamento de conteúdo personalizado. Este projeto tem como foco a utilização do Apache Cassandra para realizar uma análise aprofundada dos dados relativos às séries e filmes mais assistidos durante a semana, de acordo com a plataforma de streaming Netflix. Através da coleta de informações sobre as preferências de visualização em diferentes países, buscamos identificar padrões, tendências e variações culturais que influenciam as escolhas dos espectadores.\n",
    "\n",
    "Ao concentrar-se nos dados semanais de popularidade, este estudo busca oferecer insights valiosos sobre as preferências regionais, destacando as produções que capturaram a atenção dos telespectadores em diversos países. A escolha de utilizar o Apache Cassandra como sistema de gerenciamento de banco de dados é motivada pela sua capacidade de lidar eficientemente com grandes volumes de dados distribuídos, proporcionando uma estrutura robusta para análises escaláveis e em tempo real.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Diferença entre bancos de dados relacionais e não relacionais\n",
    "\n",
    "Bancos de dados relacionais e não relacionais representam duas abordagens distintas para armazenar e gerenciar dados.\n",
    "\n",
    "Em bancos de dados relacionais, os dados são organizados em tabelas, que consistem em linhas e colunas. Cada linha representa uma entrada única, enquanto cada coluna representa um atributo específico. Allém disso, os bancos de dados relacionais têm um esquema de dados rígido e predefinido. Antes de inserir dados, é necessário definir a estrutura da tabela, indicando os tipos de dados e relacionamentos, conhecido como integridade referencial que, por sua vez, é mantida por meio de chaves estrangeiras, que estabelecem relações entre diferentes tabelas.\n",
    "\n",
    "Já nos bancos de dados não relacionais os dados são armazenados de forma mais flexível, utilizando documentos, grafos, ou pares de chave-valor, dependendo do tipo de banco de dados utilizado.\n",
    "Com isso, não há a necessidade de um esquema pré-determinado. Sem Esquema Predeterminado: Não há necessidade de um esquema fixo. Os dados podem ser inseridos sem uma estrutura predefinida. Por conta disso, os relacionamentos podem ser mais fluidos, e não há uma dependência estrita de chaves estrangeiras.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Apresentação do problema\n",
    "\n",
    "No site oficial da Netflix é possível visualizar as séries e filmes mais assistidos do mundo, de forma global. Logo mais abaixo encontram-se uma lista de países com seus respectivos filmes mais assistidos da semana, como, por exemplo, do nosso querido Brasil. Logo embaixo da tabela há alguns arquivos no formato TSV disponíveis para baixarmos e fazermos nossas análises.\n",
    "\n",
    "Esse projeto consiste na análise das séries e filmes mais assistidos da semana em todos os países disponíveis na Netflix, desde o ano de 2021. Para isso, iremos fazer o download dessa base de dados e carregá-la no Apache Cassandra para que uma pergunta possa ser respondida: Qual foi o filme e série que ficou na primeira posição do ranque por mais semanas nos países do Brasil, Itália, Espanha e França na Netflix, para os anos de 2021, 2022 e 2023?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Infraestrutura e configuração do ambiente\n",
    "\n",
    "Para a realização desse projeto, iremos fazer o uso do Docker para a conteinerização de um cluster do Apache Cassandra. Para isso, também vamos fazer o uso do Docker Composer, uma ferramenta dentro do próprio Docker para orquestrar múltiplos serviços, definir rede e variáveis de ambientes em um único arquivo yaml.\n",
    "\n",
    "```cluster-cassandra.yaml\n",
    "services:\n",
    "  cassandra:\n",
    "    image: cassandra:latest\n",
    "    environment:\n",
    "      CQLSH_HOST: cassandra\n",
    "      CQLSH_PORT: 9042\n",
    "      CQLVERSION: 3.4.6\n",
    "    ports:\n",
    "      - 9042:9042\n",
    "\n",
    "```\n",
    "\n",
    "Depois da definição do arquivo yaml, podemos inicializar o cluster do Cassandra através do docker compose:\n",
    "\n",
    "```bash\n",
    "$ docker compose up -d\n",
    "...\n",
    "$ docker compose ps\n",
    "NAME                    IMAGE              COMMAND                  SERVICE     CREATED       STATUS          PORTS\n",
    "cassandra-cassandra-1   cassandra:latest   \"docker-entrypoint.s…\"   cassandra   6 weeks ago   Up 55 minutes   7000-7001/tcp, 7199/tcp, 9160/tcp, 0.0.0.0:9042->9042/tcp\n",
    "```\n",
    "\n",
    "Para finalizar, vamos criar o keyspace e a tabela onde nossos dados serão salvos.\n",
    "\n",
    "```CQL\n",
    "CREATE keyspace IF NOT EXISTS netflix WITH REPLICATION = { 'class': 'SimpleStrategy',\n",
    "'replication_factor': '1' };\n",
    "\n",
    "CREATE TABLE IF NOT EXISTS netflix.top10 (\n",
    "    country_name text,\n",
    "    week date,\n",
    "        rank int,\n",
    "        category text,\n",
    "    show_title text,\n",
    "    season_title text,\n",
    "    weeks_in_top10 int,\n",
    "    PRIMARY KEY (\n",
    "        (country_name, category),\n",
    "        rank,\n",
    "        weeks_in_top10,\n",
    "        week\n",
    "    )\n",
    ") WITH CLUSTERING\n",
    "ORDER BY\n",
    "    (rank ASC, weeks_in_top10 DESC, week DESC);\n",
    "\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Extração, transformação e carregamento de dados\n",
    "\n",
    "A seguir, iremos fazer a extração da base de dados do site oficial da Netflix, carregar esses dados por meio do Apache Spark, realizar algumas transformações e, por fim, salvá-los na tabela no Apache Cassandra.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1. Extração de dados\n",
    "\n",
    "A extração da base de dado da Netflix será feita por meio do utilitário da linha de comando do Unix conhecido como _wget_. O arquivo será salvo localmente com o título de top10-by-country.tsv.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2023-12-04 20:53:49--  https://www.netflix.com/tudum/top10/data/all-weeks-countries.tsv\n",
      "Resolving www.netflix.com (www.netflix.com)... 52.3.144.142, 3.230.129.93, 54.237.226.164, ...\n",
      "Connecting to www.netflix.com (www.netflix.com)|52.3.144.142|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 14685875 (14M) [text/tab-separated-values]\n",
      "Saving to: ‘top10-by-country.tsv’\n",
      "\n",
      "top10-by-country.ts 100%[===================>]  14.00M  7.94MB/s    in 1.8s    \n",
      "\n",
      "2023-12-04 20:53:51 (7.94 MB/s) - ‘top10-by-country.tsv’ saved [14685875/14685875]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget -O top10-by-country.tsv https://www.netflix.com/tudum/top10/data/all-weeks-countries.tsv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2. Transformação de dados\n",
    "\n",
    "Após a extração dos dados ser concluída, precisamos carregar os dados por meio do Apache Spark. A transformação de dados irá consistir apenas na modificação do nome de algumas colunas e remoção de outras.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "your 131072x1 screen size is bogus. expect trouble\n",
      "23/12/07 19:52:54 WARN Utils: Your hostname, geazi resolves to a loopback address: 127.0.1.1; using 172.20.61.207 instead (on interface eth0)\n",
      "23/12/07 19:52:54 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: loading settings :: url = jar:file:/home/geazi/repos/cassandra/venv/lib/python3.11/site-packages/pyspark/jars/ivy-2.5.1.jar!/org/apache/ivy/core/settings/ivysettings.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ivy Default Cache set to: /home/geazi/.ivy2/cache\n",
      "The jars for the packages stored in: /home/geazi/.ivy2/jars\n",
      "com.datastax.spark#spark-cassandra-connector_2.12 added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-a86cdff7-3a54-4f34-afdd-76ef93be1349;1.0\n",
      "\tconfs: [default]\n",
      "\tfound com.datastax.spark#spark-cassandra-connector_2.12;3.4.1 in central\n",
      "\tfound com.datastax.spark#spark-cassandra-connector-driver_2.12;3.4.1 in central\n",
      "\tfound org.scala-lang.modules#scala-collection-compat_2.12;2.11.0 in central\n",
      "\tfound com.datastax.oss#java-driver-core-shaded;4.13.0 in central\n",
      "\tfound com.datastax.oss#native-protocol;1.5.0 in central\n",
      "\tfound com.datastax.oss#java-driver-shaded-guava;25.1-jre-graal-sub-1 in central\n",
      "\tfound com.typesafe#config;1.4.1 in central\n",
      "\tfound org.slf4j#slf4j-api;1.7.26 in central\n",
      "\tfound io.dropwizard.metrics#metrics-core;4.1.18 in central\n",
      "\tfound org.hdrhistogram#HdrHistogram;2.1.12 in central\n",
      "\tfound org.reactivestreams#reactive-streams;1.0.3 in central\n",
      "\tfound com.github.stephenc.jcip#jcip-annotations;1.0-1 in central\n",
      "\tfound com.github.spotbugs#spotbugs-annotations;3.1.12 in central\n",
      "\tfound com.google.code.findbugs#jsr305;3.0.2 in central\n",
      "\tfound com.datastax.oss#java-driver-mapper-runtime;4.13.0 in central\n",
      "\tfound com.datastax.oss#java-driver-query-builder;4.13.0 in central\n",
      "\tfound org.apache.commons#commons-lang3;3.10 in central\n",
      "\tfound com.thoughtworks.paranamer#paranamer;2.8 in central\n",
      "\tfound org.scala-lang#scala-reflect;2.12.11 in central\n",
      ":: resolution report :: resolve 931ms :: artifacts dl 29ms\n",
      "\t:: modules in use:\n",
      "\tcom.datastax.oss#java-driver-core-shaded;4.13.0 from central in [default]\n",
      "\tcom.datastax.oss#java-driver-mapper-runtime;4.13.0 from central in [default]\n",
      "\tcom.datastax.oss#java-driver-query-builder;4.13.0 from central in [default]\n",
      "\tcom.datastax.oss#java-driver-shaded-guava;25.1-jre-graal-sub-1 from central in [default]\n",
      "\tcom.datastax.oss#native-protocol;1.5.0 from central in [default]\n",
      "\tcom.datastax.spark#spark-cassandra-connector-driver_2.12;3.4.1 from central in [default]\n",
      "\tcom.datastax.spark#spark-cassandra-connector_2.12;3.4.1 from central in [default]\n",
      "\tcom.github.spotbugs#spotbugs-annotations;3.1.12 from central in [default]\n",
      "\tcom.github.stephenc.jcip#jcip-annotations;1.0-1 from central in [default]\n",
      "\tcom.google.code.findbugs#jsr305;3.0.2 from central in [default]\n",
      "\tcom.thoughtworks.paranamer#paranamer;2.8 from central in [default]\n",
      "\tcom.typesafe#config;1.4.1 from central in [default]\n",
      "\tio.dropwizard.metrics#metrics-core;4.1.18 from central in [default]\n",
      "\torg.apache.commons#commons-lang3;3.10 from central in [default]\n",
      "\torg.hdrhistogram#HdrHistogram;2.1.12 from central in [default]\n",
      "\torg.reactivestreams#reactive-streams;1.0.3 from central in [default]\n",
      "\torg.scala-lang#scala-reflect;2.12.11 from central in [default]\n",
      "\torg.scala-lang.modules#scala-collection-compat_2.12;2.11.0 from central in [default]\n",
      "\torg.slf4j#slf4j-api;1.7.26 from central in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   19  |   0   |   0   |   0   ||   19  |   0   |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-a86cdff7-3a54-4f34-afdd-76ef93be1349\n",
      "\tconfs: [default]\n",
      "\t0 artifacts copied, 19 already retrieved (0kB/18ms)\n",
      "23/12/07 19:52:57 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession, Window\n",
    "from pyspark.sql.functions import col, date_format, lower, row_number\n",
    "\n",
    "\n",
    "spark = (\n",
    "    SparkSession.builder.config(\n",
    "        \"spark.jars.packages\", \"com.datastax.spark:spark-cassandra-connector_2.12:3.4.1\"\n",
    "    )\n",
    "    .config(\"spark.cassandra.connection.host\", \"localhost:9042\")\n",
    "    .getOrCreate()\n",
    ")\n",
    "\n",
    "spark.sparkContext.setLogLevel(\"ERROR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- country_name: string (nullable = true)\n",
      " |-- country_iso2: string (nullable = true)\n",
      " |-- week: date (nullable = true)\n",
      " |-- category: string (nullable = true)\n",
      " |-- weekly_rank: integer (nullable = true)\n",
      " |-- show_title: string (nullable = true)\n",
      " |-- season_title: string (nullable = true)\n",
      " |-- cumulative_weeks_in_top_10: integer (nullable = true)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "raw_top10 = spark.read.csv(\n",
    "    \"top10-by-country.tsv\", sep=\"\t\", header=True, inferSchema=True\n",
    ")\n",
    "\n",
    "raw_top10.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+----------+----+--------+----------------------+------------+--------------+\n",
      "|country_name|week      |rank|category|show_title            |season_title|weeks_in_top10|\n",
      "+------------+----------+----+--------+----------------------+------------+--------------+\n",
      "|Argentina   |2023-11-26|1   |films   |Leo                   |N/A         |1             |\n",
      "|Argentina   |2023-11-26|2   |films   |Jules                 |N/A         |1             |\n",
      "|Argentina   |2023-11-26|3   |films   |Last Call for Istanbul|N/A         |1             |\n",
      "|Argentina   |2023-11-26|4   |films   |Elena Knows           |N/A         |1             |\n",
      "|Argentina   |2023-11-26|5   |films   |See You on Venus      |N/A         |1             |\n",
      "+------------+----------+----+--------+----------------------+------------+--------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "top10 = raw_top10.select(\n",
    "    col(\"country_name\"),\n",
    "    col(\"week\"),\n",
    "    col(\"weekly_rank\").alias(\"rank\"),\n",
    "    lower(\"category\").alias(\"category\"),\n",
    "    col(\"show_title\"),\n",
    "    col(\"season_title\"),\n",
    "    col(\"cumulative_weeks_in_top_10\").alias(\"weeks_in_top10\"),\n",
    ")\n",
    "\n",
    "top10.show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.3. Carregamento de dados\n",
    "\n",
    "Por fim, depois da transformação de dados ser aplicada, vamos carregar os dados no Apache Cassandra através do Spark.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "(\n",
    "    top10.write.format(\"org.apache.spark.sql.cassandra\")\n",
    "    .option(\"keyspace\", \"netflix\")\n",
    "    .option(\"table\", \"top10\")\n",
    "    .mode(\"append\")\n",
    "    .save()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Consultas\n",
    "\n",
    "A seguir, iremos realizar duas consultas no Apache Cassandra:\n",
    "\n",
    "1. Série mais assistida do Brasil em 2023. Essa consulta será feita utilizando o Cassandra Query language (CQL).\n",
    "2. Qual foi o filme e série que ficou na primeira posição do ranque por mais semanas nos países do Brasil, Itália, Espanha e França na Netflix, para os anos de 2021, 2022 e 2023? Essa análise será feita mediante do Apache Spark.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.1. Série mais assistida do Brasil em 2023\n",
    "\n",
    "```CQL\n",
    "SELECT\n",
    "    show_title AS serie,\n",
    "    season_title AS season,\n",
    "    week\n",
    "FROM\n",
    "    netflix.top10\n",
    "WHERE\n",
    "    country_name = 'Brazil'\n",
    "    AND category = 'tv'\n",
    "    AND RANK = 1\n",
    "    AND weeks_in_top10 = 4\n",
    "    AND week >= '2023-01-01';\n",
    "\n",
    "```\n",
    "\n",
    "```output\n",
    " serie           | season                    | week\n",
    "-----------------+---------------------------+------------\n",
    " The Night Agent | The Night Agent: Season 1 | 2023-04-16\n",
    "\n",
    "(1 rows)\n",
    "\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.2. Qual foi o filme e série que ficou por mais tempo na primeira posição?\n",
    "\n",
    "Como foi dito, essa análise consiste em saber qual foi o filme e série que ficou na primeira posição do ranque por mais semanas nos países do Brasil, Itália, Espanha e França na Netflix, para os anos de 2021, 2022 e 2023?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 0:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------+----+--------------+----------+------------+--------------------+\n",
      "|country_name|category|rank|weeks_in_top10|      week|season_title|          show_title|\n",
      "+------------+--------+----+--------------+----------+------------+--------------------+\n",
      "|       Spain|   films|   1|             3|2023-09-24|         N/A|  Rosa Peral's Tapes|\n",
      "|       Spain|   films|   1|             3|2023-08-27|         N/A|      Heart of Stone|\n",
      "|       Spain|   films|   1|             3|2023-05-28|         N/A|          The Mother|\n",
      "|       Spain|   films|   1|             3|2023-03-26|         N/A|Luther: The Falle...|\n",
      "|       Spain|   films|   1|             3|2022-08-14|         N/A|       Purple Hearts|\n",
      "|       Spain|   films|   1|             3|2022-01-09|         N/A|       Don't Look Up|\n",
      "|       Spain|   films|   1|             2|2023-11-19|         N/A|          The Killer|\n",
      "|       Spain|   films|   1|             2|2023-11-12|         N/A|     Summer Vacation|\n",
      "|       Spain|   films|   1|             2|2023-10-15|         N/A|           Fair Play|\n",
      "|       Spain|   films|   1|             2|2023-10-08|         N/A|             Nowhere|\n",
      "|       Spain|   films|   1|             2|2023-09-17|         N/A|  Rosa Peral's Tapes|\n",
      "|       Spain|   films|   1|             2|2023-09-10|         N/A|   The Little Things|\n",
      "|       Spain|   films|   1|             2|2023-08-20|         N/A|      Heart of Stone|\n",
      "|       Spain|   films|   1|             2|2023-08-06|         N/A|            Paradise|\n",
      "|       Spain|   films|   1|             2|2023-07-23|         N/A|  Bird Box Barcelona|\n",
      "|       Spain|   films|   1|             2|2023-07-02|         N/A|Through My Window...|\n",
      "|       Spain|   films|   1|             2|2023-06-25|         N/A|        Extraction 2|\n",
      "|       Spain|   films|   1|             2|2023-06-11|         N/A|    A Beautiful Life|\n",
      "|       Spain|   films|   1|             2|2023-06-04|         N/A|          Tin & Tina|\n",
      "|       Spain|   films|   1|             2|2023-05-21|         N/A|          The Mother|\n",
      "+------------+--------+----+--------------+----------+------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "top10 = (\n",
    "    spark.read.format(\"org.apache.spark.sql.cassandra\")\n",
    "    .option(\"keyspace\", \"netflix\")\n",
    "    .option(\"table\", \"top10\")\n",
    "    .load()\n",
    ")\n",
    "\n",
    "top10.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 99:==============================================>         (14 + 3) / 17]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------+----+-------------------------+-----------------------+\n",
      "|country_name|category|year|title                    |weeks_in_first_position|\n",
      "+------------+--------+----+-------------------------+-----------------------+\n",
      "|Brazil      |tv      |2023|The Night Agent          |4                      |\n",
      "|Brazil      |films   |2023|Nowhere                  |2                      |\n",
      "|Brazil      |tv      |2022|Stranger Things          |5                      |\n",
      "|Brazil      |films   |2022|The Royal Treatment      |2                      |\n",
      "|Brazil      |tv      |2021|Carrossel                |7                      |\n",
      "|Brazil      |films   |2021|Major Grom: Plague Doctor|2                      |\n",
      "|France      |tv      |2023|You                      |4                      |\n",
      "|France      |films   |2023|The Mother               |3                      |\n",
      "|France      |tv      |2022|Stranger Things          |5                      |\n",
      "|France      |films   |2022|The Tinder Swindler      |3                      |\n",
      "|France      |tv      |2021|Squid Game               |4                      |\n",
      "|France      |films   |2021|Kate                     |2                      |\n",
      "|Italy       |tv      |2023|The Sea Beyond           |7                      |\n",
      "|Italy       |films   |2023|Heart of Stone           |3                      |\n",
      "|Italy       |tv      |2022|Stranger Things          |7                      |\n",
      "|Italy       |films   |2022|The Adam Project         |3                      |\n",
      "|Italy       |tv      |2021|Squid Game               |6                      |\n",
      "|Italy       |films   |2021|Army of Thieves          |2                      |\n",
      "|Spain       |films   |2023|Heart of Stone           |3                      |\n",
      "|Spain       |tv      |2023|Lupin                    |3                      |\n",
      "|Spain       |tv      |2022|Café con aroma de mujer  |11                     |\n",
      "|Spain       |films   |2022|Through My Window        |2                      |\n",
      "|Spain       |tv      |2021|Squid Game               |7                      |\n",
      "|Spain       |films   |2021|The Unforgivable         |2                      |\n",
      "+------------+--------+----+-------------------------+-----------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "countries = (\"Brazil\", \"Italy\", \"Spain\", \"France\")\n",
    "window_spec = Window.partitionBy(\"country_name\", \"category\", \"year\").orderBy(\n",
    "    col(\"rank\").asc(), col(\"weeks_by_rank\").desc()\n",
    ")\n",
    "\n",
    "first_positions = (\n",
    "    top10.withColumn(\"year\", date_format(\"week\", \"yyyy\").cast(\"INTEGER\"))\n",
    "    .groupBy(\"country_name\", \"category\", \"year\", \"show_title\", \"rank\")\n",
    "    .agg(count(\"*\").alias(\"weeks_by_rank\"))\n",
    "    .withColumn(\"row_number\", row_number().over(window_spec))\n",
    "    .filter(\n",
    "        (col(\"row_number\") == 1)\n",
    "        & (col(\"rank\") == 1)\n",
    "        & (col(\"country_name\").isin(*countries))\n",
    "    )\n",
    "    .orderBy(\"country_name\", \"year\", \"weeks_by_rank\", ascending=[True, False, False])\n",
    "    .select(\n",
    "        \"country_name\",\n",
    "        \"category\",\n",
    "        \"year\",\n",
    "        col(\"show_title\").alias(\"title\"),\n",
    "        col(\"weeks_by_rank\").alias(\"weeks_in_first_position\"),\n",
    "    )\n",
    ")\n",
    "\n",
    "first_positions.show(24, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Salvamento dos dados\n",
    "\n",
    "Por fim, iremos salvar esses dados que acabamos de analisar localmente no formato CSV.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "first_positions.coalesce(1).write.csv(\"first_positions.csv\", header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Considerações finais\n",
    "\n",
    "Este projeto, centrado na análise dos filmes e séries mais assistidos da semana em cada país na plataforma Netflix, revelou-se uma jornada elucidativa no universo da análise de dados para o entretenimento digital.\n",
    "\n",
    "A escolha estratégica do Apache Cassandra como sistema de gerenciamento de banco de dados proporcionou uma infraestrutura robusta e distribuída, capaz de lidar eficientemente com grandes volumes de dados provenientes de diferentes regiões do globo.\n",
    "\n",
    "A utilização do Apache Spark para a análise desses dados revelou-se fundamental, permitindo-nos extrair insights valiosos, identificar padrões de visualização e compreender as nuances das preferências de audiência em diferentes contextos culturais.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
